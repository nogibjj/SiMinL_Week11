

# SiMinL_MiniProj11

# Requirements
Create a data pipeline using Databricks
Include at least one data source and one data sink
Databricks notebook or script
Document or video demonstrating the pipeline

# Purpose 
Overview: This repository provides an ETL pipeline using PySpark within Databricks to extract data from an external source, transform it for analysis, and load it into a Databricks Delta table.

# Components
1. Create the Cluster
![alt text](image-1.png)
2. Import Github repo
![alt text](image.png)
3. Perform ETL
Extract: From the source
Transform: Clean and structure with PySpark
Load: Insert transformed data into a Delta table in Databricks
4. Run the job
